{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import applications\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'input/train'\n",
    "test_data_dir = 'input/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "class_labels = os.listdir(test_data_dir)\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "neg 1187\n",
      "pos 2430\n",
      "test ----- 3617\n",
      "train\n",
      "neg 3894\n",
      "pos 2630\n",
      "train ----- 6524\n"
     ]
    }
   ],
   "source": [
    "for wdir in os.listdir('input'):\n",
    "    print(wdir)\n",
    "    wdir_total = 0\n",
    "    for label in class_labels:\n",
    "        total = len(os.listdir(os.path.join('input', wdir, label)))\n",
    "        print(label, total)\n",
    "        wdir_total +=total\n",
    "    print(wdir,'-----',wdir_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples =6524\n",
    "nb_test_samples = 3617\n",
    "num_classes = 2\n",
    "img_rows=64 \n",
    "img_cols= 64\n",
    "channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data():\n",
    "    labels = os.listdir(train_data_dir)\n",
    "    print(labels)\n",
    "    total = len(labels)\n",
    "    \n",
    "    X_train = np.ndarray((nb_train_samples, img_rows, img_cols, 3), dtype = np.uint8)\n",
    "    Y_train = np.zeros((nb_train_samples,), dtype = np.uint8)\n",
    "    \n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating training images...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    j = 0\n",
    "    for label in labels:\n",
    "        image_names_train = os.listdir(os.path.join(train_data_dir, label))\n",
    "        total = len(image_names_train)\n",
    "        print(label, total)\n",
    "        for image_name in image_names_train:\n",
    "            img = cv2.imread(os.path.join(train_data_dir, label, image_name), 1)\n",
    "            img = np.array(cv2.resize(img, (img_rows,img_cols)))\n",
    "            X_train[i] = img\n",
    "            Y_train[i] = j\n",
    "\n",
    "            if i % 800 == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, total))\n",
    "            i += 1\n",
    "        j += 1    \n",
    "    print(str(i) +\"-------\"+ str(j))                \n",
    "    print('Loading done.')\n",
    "    \n",
    "    print('Transform targets to keras compatible format.')\n",
    "    Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
    "\n",
    "    np.save('dataset/imgs_train.npy', X_train, Y_train)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_data():\n",
    "    labels = os.listdir(test_data_dir)\n",
    "    \n",
    "\n",
    "    X_test = np.ndarray((nb_test_samples, img_rows, img_cols, 3), dtype=np.uint8)\n",
    "    Y_test = np.zeros((nb_test_samples,), dtype='uint8')\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating validation images...')\n",
    "    print('-'*30)\n",
    "    j = 0\n",
    "    for label in labels:\n",
    "        image_names_test = os.listdir(os.path.join(test_data_dir, label))\n",
    "        total = len(image_names_test)\n",
    "        print(label, total)\n",
    "        for image_name in image_names_test:\n",
    "            img = cv2.imread(os.path.join(test_data_dir, label, image_name), 1)\n",
    "\n",
    "            img = np.array(cv2.resize(img, (img_rows,img_cols)))\n",
    "\n",
    "            X_test[i] = img\n",
    "            Y_test[i] = j\n",
    "\n",
    "            if i % 200 == 0:\n",
    "                print('Done: {0}/{1} images'.format(i, total))\n",
    "            i += 1\n",
    "        j += 1\n",
    "    print(i)            \n",
    "    print('Loading done.')\n",
    "    \n",
    "    print('Transform targets to keras compatible format.');\n",
    "    Y_test = np_utils.to_categorical(Y_test[:nb_test_samples], num_classes)\n",
    "\n",
    "    np.save('dataset/imgs_test.npy', X_test, Y_test)\n",
    "    \n",
    "    return X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n",
      "------------------------------\n",
      "Creating training images...\n",
      "------------------------------\n",
      "neg 3894\n",
      "Done: 0/3894 images\n",
      "Done: 800/3894 images\n",
      "Done: 1600/3894 images\n",
      "Done: 2400/3894 images\n",
      "Done: 3200/3894 images\n",
      "pos 2630\n",
      "Done: 4000/2630 images\n",
      "Done: 4800/2630 images\n",
      "Done: 5600/2630 images\n",
      "Done: 6400/2630 images\n",
      "6524-------2\n",
      "Loading done.\n",
      "Transform targets to keras compatible format.\n",
      "------------------------------\n",
      "Creating validation images...\n",
      "------------------------------\n",
      "neg 1187\n",
      "Done: 0/1187 images\n",
      "Done: 200/1187 images\n",
      "Done: 400/1187 images\n",
      "Done: 600/1187 images\n",
      "Done: 800/1187 images\n",
      "Done: 1000/1187 images\n",
      "pos 2430\n",
      "Done: 1200/2430 images\n",
      "Done: 1400/2430 images\n",
      "Done: 1600/2430 images\n",
      "Done: 1800/2430 images\n",
      "Done: 2000/2430 images\n",
      "Done: 2200/2430 images\n",
      "Done: 2400/2430 images\n",
      "Done: 2600/2430 images\n",
      "Done: 2800/2430 images\n",
      "Done: 3000/2430 images\n",
      "Done: 3200/2430 images\n",
      "Done: 3400/2430 images\n",
      "Done: 3600/2430 images\n",
      "3617\n",
      "Loading done.\n",
      "Transform targets to keras compatible format.\n"
     ]
    }
   ],
   "source": [
    "#load data for training\n",
    "x_train, y_train = load_training_data()\n",
    "x_test, y_test = load_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6524, 64, 64, 3) (6524, 2) (3617, 64, 64, 3) (3617, 2)\n"
     ]
    }
   ],
   "source": [
    "#print the shape of the data\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 16 18]\n"
     ]
    }
   ],
   "source": [
    "# R G B\n",
    "print(x_train[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 127.5\n",
    "x_test /= 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13333334 0.1254902  0.14117648]\n",
      " [0.1254902  0.10980392 0.10980392]\n",
      " [0.15686275 0.14901961 0.16470589]\n",
      " [0.6666667  0.69803923 0.78431374]\n",
      " [0.6745098  0.7294118  0.84705883]\n",
      " [0.6901961  0.7607843  0.87058824]\n",
      " [0.7137255  0.78431374 0.89411765]\n",
      " [0.83137256 0.89411765 1.027451  ]\n",
      " [0.49411765 0.5647059  0.6745098 ]\n",
      " [0.80784315 0.8784314  0.9882353 ]\n",
      " [0.8784314  0.9490196  1.0588236 ]\n",
      " [0.9882353  1.0509804  1.2       ]\n",
      " [1.1058824  1.2156863  1.3568628 ]\n",
      " [1.0196079  1.1137255  1.254902  ]\n",
      " [0.9647059  1.0509804  1.2078432 ]\n",
      " [0.85490197 0.91764706 1.027451  ]\n",
      " [0.9098039  0.95686275 1.0431373 ]\n",
      " [0.3764706  0.42352942 0.47843137]\n",
      " [0.23529412 0.24313726 0.27450982]\n",
      " [0.2509804  0.2509804  0.2509804 ]\n",
      " [0.25882354 0.25882354 0.3137255 ]\n",
      " [0.29803923 0.26666668 0.3137255 ]\n",
      " [0.30588236 0.2901961  0.3372549 ]\n",
      " [0.32156864 0.32156864 0.36862746]\n",
      " [0.36078432 0.3529412  0.38431373]\n",
      " [0.4        0.36862746 0.41568628]\n",
      " [0.40784314 0.39215687 0.39215687]\n",
      " [0.47843137 0.40784314 0.43137255]\n",
      " [0.54901963 0.4627451  0.47843137]\n",
      " [0.6117647  0.5176471  0.5176471 ]\n",
      " [0.6901961  0.5803922  0.59607846]\n",
      " [0.74509805 0.63529414 0.6431373 ]\n",
      " [0.8235294  0.69803923 0.7058824 ]\n",
      " [0.9411765  0.7921569  0.8156863 ]\n",
      " [1.0431373  0.8784314  0.87058824]\n",
      " [1.1058824  0.9490196  0.9411765 ]\n",
      " [1.2078432  1.0431373  1.0588236 ]\n",
      " [1.2784314  1.1215687  1.1137255 ]\n",
      " [1.3960785  1.2784314  1.2862746 ]\n",
      " [1.6078432  1.482353   1.4901961 ]\n",
      " [1.6784314  1.5058824  1.5215687 ]\n",
      " [1.5372549  1.372549   1.3960785 ]\n",
      " [1.3803922  1.2156863  1.2392157 ]\n",
      " [1.2627451  1.0588236  1.0588236 ]\n",
      " [1.137255   0.95686275 0.9490196 ]\n",
      " [1.0666667  0.8784314  0.89411765]\n",
      " [0.9647059  0.8        0.8235294 ]\n",
      " [0.87058824 0.72156864 0.74509805]\n",
      " [0.74509805 0.6117647  0.63529414]\n",
      " [0.627451   0.5411765  0.5568628 ]\n",
      " [0.5411765  0.4627451  0.4627451 ]\n",
      " [0.47843137 0.41568628 0.42352942]\n",
      " [0.4392157  0.39215687 0.4       ]\n",
      " [0.41568628 0.3764706  0.38431373]\n",
      " [0.36078432 0.3372549  0.3529412 ]\n",
      " [0.32156864 0.2901961  0.28235295]\n",
      " [0.30588236 0.2901961  0.2901961 ]\n",
      " [0.22745098 0.26666668 0.25882354]\n",
      " [0.22745098 0.23529412 0.26666668]\n",
      " [0.28235295 0.28235295 0.32941177]\n",
      " [0.36862746 0.41568628 0.44705883]\n",
      " [0.36862746 0.5411765  0.5176471 ]\n",
      " [0.27450982 0.38431373 0.3764706 ]\n",
      " [0.32941177 0.40784314 0.4627451 ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vgg16_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows,img_rows,channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = Model(vgg16_model.input, vgg16_model.get_layer('block5_conv2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vgg16_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=vgg16_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 12,882,242\n",
      "Trainable params: 12,882,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001, decay=1e-6) \n",
    "size = 32\n",
    "epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss= 'categorical_crossentropy',\n",
    "    optimizer=adam,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6524 samples, validate on 3617 samples\n",
      "Epoch 1/5\n",
      "6524/6524 [==============================] - 1559s 239ms/step - loss: 0.0891 - acc: 0.9700 - val_loss: 2.7778 - val_acc: 0.6967\n",
      "Epoch 2/5\n",
      "6524/6524 [==============================] - 1555s 238ms/step - loss: 0.0214 - acc: 0.9946 - val_loss: 2.4318 - val_acc: 0.6638\n",
      "Epoch 3/5\n",
      "6524/6524 [==============================] - 1586s 243ms/step - loss: 4.2069e-04 - acc: 0.9998 - val_loss: 3.2400 - val_acc: 0.6821\n",
      "Epoch 4/5\n",
      "6524/6524 [==============================] - 1550s 238ms/step - loss: 2.9289e-04 - acc: 0.9998 - val_loss: 3.1275 - val_acc: 0.6505\n",
      "Epoch 5/5\n",
      "6524/6524 [==============================] - 1871s 287ms/step - loss: 2.7010e-04 - acc: 0.9998 - val_loss: 3.3863 - val_acc: 0.6544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c90755bf60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=size,\n",
    "    epochs=epoch,\n",
    "    validation_data=(x_test, y_test),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.0745611e-01 2.9254386e-01]\n",
      " [4.3463212e-02 9.5653683e-01]\n",
      " [6.8580657e-03 9.9314195e-01]\n",
      " ...\n",
      " [9.9999762e-01 2.4261003e-06]\n",
      " [9.9999750e-01 2.4450860e-06]\n",
      " [9.9999774e-01 2.2867632e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3617"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = []\n",
    "for i in range(0, len(y_pred)):\n",
    "    y_predict.append(int(np.argmax(y_pred[i])))\n",
    "len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3617"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = []\n",
    "for i in range(0, len(y_test)):\n",
    "    y_true.append(int(np.argmax(y_test[i])))\n",
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.57      0.52      1187\n",
      "          1       0.77      0.70      0.73      2430\n",
      "\n",
      "avg / total       0.67      0.65      0.66      3617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true,y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to plot confusion matrix\n",
    "cm = confusion_matrix(y_true=y_true, y_pred=y_predict)\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3617/3617 [==============================] - 263s 73ms/step\n",
      "Loss Value :  3.3863168589616075\n",
      "Accuracy :  0.654409731821952\n"
     ]
    }
   ],
   "source": [
    "# model performance\n",
    "score = model.evaluate(x= x_test, y= y_test, batch_size=32)\n",
    "acc = score[1]\n",
    "err = 1 - acc\n",
    "print(\"Loss Value : \", score[0])\n",
    "print(\"Accuracy : \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10868"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_structure = model.to_json()\n",
    "f = Path(\"model/model_structure.json\")\n",
    "f.write_text(model_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model/model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys(f):\n",
    "    return [items for items in f.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['block1_conv1',\n",
       " 'block1_conv2',\n",
       " 'block1_pool',\n",
       " 'block2_conv1',\n",
       " 'block2_conv2',\n",
       " 'block2_pool',\n",
       " 'block3_conv1',\n",
       " 'block3_conv2',\n",
       " 'block3_conv3',\n",
       " 'block3_pool',\n",
       " 'block4_conv1',\n",
       " 'block4_conv2',\n",
       " 'block4_conv3',\n",
       " 'block4_pool',\n",
       " 'block5_conv1',\n",
       " 'block5_conv2',\n",
       " 'dense_1',\n",
       " 'dropout_1',\n",
       " 'global_average_pooling2d_1',\n",
       " 'input_1',\n",
       " 'predictions']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"model/model_weights.h5\"\n",
    "h5 = h5py.File(filename,'r')\n",
    "keys(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
